{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.         0.23529412 0.2683706  0.11383499 0.75       0.42857143\n",
      "  0.9302326  0.8333333  0.21875    0.38620284 0.         0.2310231\n",
      "  0.35714287 0.33892617 0.65363127 0.         0.63860667 0.33333334\n",
      "  0.         0.6666667  0.5        0.6666667  0.         0.6666667\n",
      "  0.33333334 0.99502486 0.75       0.6014388  0.26086956 0.23076923\n",
      "  0.         0.         0.         0.         0.         1.\n",
      "  0.5       ]] [0.4996381]\n",
      "[[2.         0.23529412 0.2172524  0.08739647 0.625      0.42857143\n",
      "  0.93798447 0.8666667  0.10125    0.2865566  0.         0.20462047\n",
      "  0.28696194 0.23106425 0.5375543  0.         0.48911467 0.33333334\n",
      "  0.         0.6666667  0.5        0.5        0.         0.33333334\n",
      "  0.33333334 0.9955224  0.5        0.4374101  0.         0.11538462\n",
      "  0.         0.         0.         0.         0.         0.72727275\n",
      "  0.5       ]] [0.4379656]\n",
      "[[12.          0.          0.29073483  0.0821439   0.625       0.42857143\n",
      "   0.9767442   0.95        0.19125     0.          0.          0.70438474\n",
      "   0.46600124  0.506232    0.          0.          0.38316402  0.\n",
      "   0.          0.6666667   0.          0.5         0.          0.44444445\n",
      "   0.33333334  0.99801     0.75        0.60431653  0.2173913   0.09065934\n",
      "   0.          0.          0.          0.          0.          0.6363636\n",
      "   0.25      ]] [0.56829244]\n",
      "[[6.         0.         0.23961662 0.07715483 0.75       0.42857143\n",
      "  0.9612403  0.9166667  0.11625    0.8071934  0.         0.1494578\n",
      "  0.525889   0.6021093  0.         0.         0.45573294 0.33333334\n",
      "  0.         0.6666667  0.         0.5        0.         0.44444445\n",
      "  0.33333334 0.99701494 0.5        0.45755395 0.3464674  0.15659341\n",
      "  0.         0.         0.         0.         0.         0.6363636\n",
      "  0.25      ]] [0.6322922]\n",
      "[[24.          0.          0.19169329  0.05182303  0.375       0.71428573\n",
      "   0.5503876   0.8333333   0.          0.1379717   0.32971507  0.08486563\n",
      "   0.28072363  0.22147651  0.          0.          0.16763425  0.\n",
      "   0.5         0.33333334  0.          0.5         0.          0.22222222\n",
      "   0.          0.99751246  0.5         0.41438848  0.30163044  0.08791209\n",
      "   0.          0.          0.          0.          0.          0.36363637\n",
      "   1.        ]] [0.23153722]\n",
      "[[11.          0.          0.          0.10248663  0.375       0.5714286\n",
      "   0.6356589   0.2         0.          0.4345519   0.          0.08250825\n",
      "   0.28446662  0.22722915  0.          0.          0.17198838  0.33333334\n",
      "   0.          0.33333334  0.          0.33333334  0.          0.11111111\n",
      "   0.          0.9761194   0.25        0.2532374   0.19021739  0.\n",
      "   0.          0.          0.45714286  0.          0.          0.72727275\n",
      "   0.5       ]] [0.25294808]\n",
      "[[18.          0.          0.22364217  0.05498511  0.375       0.5714286\n",
      "   0.60465115  0.25        0.          0.2971698   0.          0.24752475\n",
      "   0.3209607   0.43192714  0.          0.          0.32692307  0.\n",
      "   0.          0.33333334  0.          0.5         0.          0.33333334\n",
      "   0.          0.9741294   0.25        0.21151079  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.36363637\n",
      "   0.75      ]] [0.24131174]\n",
      "[[14.          0.14705883  0.1629393   0.04233678  0.625       0.85714287\n",
      "   0.37984496  0.85        0.          0.          0.          0.3922678\n",
      "   0.2595134   0.19942474  0.          0.          0.1509434   0.\n",
      "   0.          0.33333334  0.          0.33333334  0.          0.22222222\n",
      "   0.          0.99054724  0.5         0.41438848  0.06521739  0.30769232\n",
      "   0.          0.          0.          0.          0.          0.54545456\n",
      "   0.25      ]] [0.22502089]\n",
      "[[6.         0.         0.23961662 0.07715483 0.75       0.42857143\n",
      "  0.9612403  0.9166667  0.11625    0.8071934  0.         0.1494578\n",
      "  0.525889   0.6021093  0.         0.         0.45573294 0.33333334\n",
      "  0.         0.6666667  0.         0.5        0.         0.44444445\n",
      "  0.33333334 0.99701494 0.5        0.45755395 0.3464674  0.15659341\n",
      "  0.         0.         0.         0.         0.         0.6363636\n",
      "  0.25      ]] [0.6322922]\n",
      "[[9.         0.         0.22364217 0.08695728 0.375      0.42857143\n",
      "  0.65891474 0.25       0.         0.5341981  0.         0.06317775\n",
      "  0.32439175 0.2885906  0.         0.         0.21843252 0.33333334\n",
      "  0.         0.33333334 0.         0.5        0.         0.22222222\n",
      "  0.         0.97761196 0.25       0.276259   0.         0.\n",
      "  0.         0.         0.         0.         0.         0.09090909\n",
      "  0.5       ]] [0.21920273]\n",
      "[[12.          0.          0.29073483  0.0821439   0.625       0.42857143\n",
      "   0.9767442   0.95        0.19125     0.          0.          0.70438474\n",
      "   0.46600124  0.506232    0.          0.          0.38316402  0.\n",
      "   0.          0.6666667   0.          0.5         0.          0.44444445\n",
      "   0.33333334  0.99801     0.75        0.60431653  0.2173913   0.09065934\n",
      "   0.          0.          0.          0.          0.          0.6363636\n",
      "   0.25      ]] [0.56829244]\n",
      "[[5.         0.1764706  0.2715655  0.11256137 0.375      0.42857143\n",
      "  0.875969   0.75       0.         0.43160376 0.         0.03017445\n",
      "  0.24828447 0.17162032 0.35133457 0.         0.3352685  0.33333334\n",
      "  0.         0.33333334 0.5        0.16666667 0.         0.22222222\n",
      "  0.         0.9915423  0.5        0.34532374 0.05434782 0.08241758\n",
      "  0.         0.62992126 0.         0.         0.04516129 0.8181818\n",
      "  0.75      ]] [0.2506208]\n",
      "[[19.          0.14705883  0.18210863  0.05401014  0.625       0.71428573\n",
      "   0.3875969   0.          0.          0.          0.          0.30033004\n",
      "   0.19868995  0.32118887  0.          0.          0.24310595  0.\n",
      "   0.          0.33333334  0.          0.5         0.          0.33333334\n",
      "   0.33333334  0.960199    0.25        0.20143884  0.          0.\n",
      "   0.6212121   0.          0.          0.          0.          0.45454547\n",
      "   0.25      ]] [0.24224265]\n",
      "[[9.         0.         0.22364217 0.08695728 0.375      0.42857143\n",
      "  0.65891474 0.25       0.         0.5341981  0.         0.06317775\n",
      "  0.32439175 0.2885906  0.         0.         0.21843252 0.33333334\n",
      "  0.         0.33333334 0.         0.5        0.         0.22222222\n",
      "  0.         0.97761196 0.25       0.276259   0.         0.\n",
      "  0.         0.         0.         0.         0.         0.09090909\n",
      "  0.5       ]] [0.21920273]\n",
      "[[6.         0.         0.23961662 0.07715483 0.75       0.42857143\n",
      "  0.9612403  0.9166667  0.11625    0.8071934  0.         0.1494578\n",
      "  0.525889   0.6021093  0.         0.         0.45573294 0.33333334\n",
      "  0.         0.6666667  0.         0.5        0.         0.44444445\n",
      "  0.33333334 0.99701494 0.5        0.45755395 0.3464674  0.15659341\n",
      "  0.         0.         0.         0.         0.         0.6363636\n",
      "  0.25      ]] [0.6322922]\n",
      "Epoca 2: [[0.09381981 0.0608517  0.05973359 0.06056373 0.05817651 0.05908468\n",
      "  0.05695105 0.05711302 0.06025338 0.05990332 0.06092771 0.05874389\n",
      "  0.0589209  0.05872588 0.06083833 0.06092771 0.0592046  0.06046208\n",
      "  0.06092771 0.05817473 0.06081428 0.05885943 0.06092771 0.0590636\n",
      "  0.05955718 0.05689043 0.05811837 0.05859727 0.05989542 0.06046391\n",
      "  0.06087128 0.06079997 0.06092771 0.06092771 0.06091366 0.05822699\n",
      "  0.0597734 ]]\n",
      "0.020942712INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: shuffle_batch_26/random_shuffle_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch_26/random_shuffle_queue, stack_26, DecodeCSV_26:37)]]\n",
      " 0.25430077\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer_38/input_producer_38_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_producer_38, input_producer_38/Const, ^input_producer_38/Assert/Assert)]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "DATA_PATH = \"./data/TRAIN.csv\"\n",
    "BATCH_SIZE = 1\n",
    "N_COLUMNS = 38\n",
    "TRAIN_STEPS = 3\n",
    "N_SAMPLES = 5\n",
    "\n",
    "def batch_generator(filename):\n",
    "    filename_queue = tf.train.string_input_producer(filename)\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    _, value = reader.read(filename_queue)\n",
    "\n",
    "    record_defaults = [[1.0] for _ in range(N_COLUMNS)]\n",
    "\n",
    "    # read in batch rows of data\n",
    "    content = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "    #pack all 37 features into a tensor\n",
    "    features = tf.stack(content[:N_COLUMNS-1])\n",
    "\n",
    "    #last column to label\n",
    "    label = content[-1]\n",
    "\n",
    "    min_after_dequeue = 20\n",
    "\n",
    "    capacity = 21\n",
    "\n",
    "    data_batch, label_batch = tf.train.shuffle_batch([features, label], batch_size=BATCH_SIZE, capacity=capacity, min_after_dequeue=min_after_dequeue)\n",
    "    return data_batch, label_batch\n",
    "\n",
    "def generate_batches(data_batch, label_batch):\n",
    "    with tf.Session() as sess:\n",
    "        try:\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(coord=coord)\n",
    "            for _ in range(TRAIN_STEPS):\n",
    "                features, labels = sess.run([data_batch, label_batch])\n",
    "                print(features,\" + \", labels)\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done training -- limit reached')\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "\n",
    "#define placehodelrs\n",
    "X = tf.placeholder(tf.float32,name=\"X\")\n",
    "Y = tf.placeholder(tf.float32,name=\"Y\")\n",
    "\n",
    "#create weight and bias\n",
    "W = tf.Variable(0.0, name=\"weight\", dtype=tf.float32)\n",
    "b = tf.Variable(0.0, name=\"bias\", dtype=tf.float32)\n",
    "\n",
    "#Predict\n",
    "Y_pred = X*W + b\n",
    "\n",
    "#loss\n",
    "loss = tf.square(Y-Y_pred, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        writer = tf.summary.FileWriter(\"./graphs/linearReg\", sess.graph)\n",
    "        for i in range(TRAIN_STEPS):\n",
    "            total_loss = 0.0\n",
    "            data_batch, label_batch = batch_generator([DATA_PATH])\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(coord=coord)\n",
    "            for _ in range(N_SAMPLES):\n",
    "                features, labels = sess.run([data_batch, label_batch])\n",
    "                print(features, labels)\n",
    "                _, loss_per_step = sess.run([optimizer, loss], feed_dict={X:features, Y:labels})\n",
    "                total_loss += loss_per_step\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- limit reached')\n",
    "    finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "            \n",
    "            print(\"Epoca {0}: {1}\".format(i, total_loss/N_SAMPLES))\n",
    "            writer.close()\n",
    "\n",
    "        \n",
    "    W, b = sess.run([W, b])\n",
    "\n",
    "print(W,b)\n",
    "\n",
    "#def main():\n",
    "#    data_batch, label_batch = batch_generator([DATA_PATH])\n",
    "#    generate_batches(data_batch, label_batch)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
